{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebde2cb",
   "metadata": {},
   "source": [
    "Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2606fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pdfplumber --user\n",
    "# pip install requests --user\n",
    "# pip install tika --user\n",
    "# pip install BeautifulSoup --user\n",
    "# pip install urllib --user\n",
    "# pip install time --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f0f41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37a36d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Yeni klasÃ¶r\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import tika\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from tika import parser\n",
    "from time import strftime, sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2326f54",
   "metadata": {},
   "source": [
    "This project has been developed for data scraping from monthly added PDF reports on the Mortgage Finance Forecast Archives website (https://www.mba.org/news-and-research/forecasts-and-commentary/mortgage-finance-forecast-archives). The data scraping framework developed in this project converts the tabular data in PDF files to \".csv\" format. The developed data scraping framework integrates two different tasks such as web scraping and data extraction. The code uses three different function named as extract_table_columns_name, extract_pdf_data, and get_pdf_files. The get_pdf_files function downloads the pdf files from the archive, and then extracts tabular data and attribute names using extract_pdf_data and extract_table_columns_name functions. The entire structure of the data scraping framework checks out the archive manually for newly added reports and works as a fully automated manner. Besides, the regex expressions in the framework are also compatible with pattern formats that vary in different table structures.\n",
    "\n",
    "In this project, two different packages used for data extraction from PDF files: pdfplumber and tika-python. At the stage of web scraping, the url links of the pdf files are parsed using lxml feature of the BeautifulSoup package.  \n",
    "\n",
    "When the code is run for the first time, it creates two files named as archievefiles, archievecsvfiles and it also creates a \".csv\" file named as archievelinks in cwd. When the code is run for the second time, it only downloads the pdf files in the newly added url links to the archive and performs other operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f556e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_columns_name(text):\n",
    "    text = text.replace('\\n\\n', '\\n')\n",
    "    text = text.rstrip('\\r\\n')\n",
    "    eee = re.compile(r\"^([\\w,(+\\- \\d%]+[A-Za-z_$)]+) {1,4}([\\d+]+.*)\")\n",
    "    eee2 = re.compile(r\"^(?!([\\w,(+\\- \\d%]+[A-Za-z_$)]+) {1,4}([\\d+]+.*)).*|^[A-Z]+ [A-Za-z]+ \\(\\w+ \\$\\)\")\n",
    "    columns_subnames = []\n",
    "    columns_upnames = []\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        if eee.match(line):\n",
    "            line = re.search(eee,line)\n",
    "            subnames = line.group(1)\n",
    "            columns_subnames.append(subnames)\n",
    "        else:\n",
    "            columns_subnames.append('')\n",
    "    for line in text.split('\\n'):\n",
    "        if eee2.match(line):\n",
    "            line = re.search(eee2,line)\n",
    "            upnames = line.group(0)\n",
    "            columns_upnames.append(upnames)\n",
    "        else:\n",
    "            columns_upnames.append('')\n",
    "    df1 = pd.DataFrame(columns_upnames)\n",
    "    df1 = df1.replace('', np.nan).ffill(axis ='rows')\n",
    "    df2 = pd.DataFrame(columns_subnames)\n",
    "    index1 = (df2[0] == \"\")\n",
    "    df1 = df1[index1==False]\n",
    "    df2 = df2[df2[0] != \"\"]\n",
    "    df3 = df1[0] + ':' + df2[0]\n",
    "    index2 = df1[0] == df2[0]\n",
    "    index_final = index1 | index2\n",
    "    df3 = df3[index_final==False]\n",
    "    time_information = pd.DataFrame([\"file_date\",\"Year\",\"Quarter\"])\n",
    "    df_final = pd.concat([time_information, df3]).reset_index(drop = True)\n",
    "    columns_name = df_final.values\n",
    "    \n",
    "    return columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54964bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_data(pattern4):\n",
    "    with pdfplumber.open(\"./archievefiles/\"+pattern4) as pdf:\n",
    "        page = pdf.pages[0]\n",
    "        text = page.extract_text()\n",
    "    file_date_pattern = r\"(\\w+ \\d+), (\\d{4})\"\n",
    "    date_output = re.search(file_date_pattern, text).group()\n",
    "    file_date = datetime.strptime(date_output, '%B %d, %Y').strftime('%Y-%m-%d')\n",
    "    Year_pattern_1 = r\"(\\d{4} \\d{4} \\d{4})\"\n",
    "    Year_output_1 = re.search(Year_pattern_1, text).group()\n",
    "    Year_output_1 = Year_output_1.split(\" \")\n",
    "    Year_output_1 = np.array(Year_output_1)\n",
    "    Year_output_1 = np.repeat(Year_output_1, 4)\n",
    "    Year_pattern_2 = r\"(Q4\\s)(20.*\\b\\d{4})\"\n",
    "    Year_output_2 = re.search(Year_pattern_2, text).groups()\n",
    "    Year_output_2 = Year_output_2[1].split(\" \")\n",
    "    Year_output_2 = np.array(Year_output_2)\n",
    "    Year = np.append(Year_output_1, Year_output_2)\n",
    "    text_Quarter = text[text.rfind(\"MBA Mortgage Finance Forecast\"):text.rfind(\"Housing Measures\")]\n",
    "    Quarter_pattern = r\"([Q][1-4])\"\n",
    "    Quarter_output_1 = re.findall(Quarter_pattern, text_Quarter)\n",
    "    Quarter_output_1 = np.array(Quarter_output_1)\n",
    "    Quarter_output_2 = np.full(len(Year_output_2), \"None\")\n",
    "    Quarter = np.append(Quarter_output_1, Quarter_output_2)\n",
    "    parsed = parser.from_file(\"./archievefiles/\"+pattern4)\n",
    "    text = parsed['content']\n",
    "    text = text[text.rfind(\"Housing Measures\"):text.rfind(\"Notes\")]\n",
    "    text = ''.join(str(text).replace(',',''))\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    eee = re.compile(r\"^([\\w,(+\\- \\d%]+[A-Za-z_$)]+) {1,4}([\\d+]+.*)\")\n",
    "    line_items = []\n",
    "    for line in text.split('\\n'):\n",
    "        if eee.match(line):\n",
    "            line = re.search(eee,line)        \n",
    "            values = line.group(2)\n",
    "            if len(values.split(\" \"))>=12:\n",
    "                line_items.append(values)\n",
    "                new = np.asarray(line_items)\n",
    "    columns_name = extract_table_columns_name(text)\n",
    "    columns_name = columns_name.tolist()\n",
    "    columns_name = np.reshape(columns_name, -1).tolist()\n",
    "    new = np.asarray(new)\n",
    "    df = pd.DataFrame(new)\n",
    "    df = df[0].str.split(' ', expand=True)\n",
    "    df = df.iloc[:, :-1]\n",
    "    df = df.T\n",
    "    column_date = np.repeat(file_date, len(df))\n",
    "    arr = np.vstack((column_date, Year, Quarter))\n",
    "    df2 = pd.DataFrame(arr)\n",
    "    frames = [df2.T, df]  \n",
    "    result = pd.concat(frames, axis=1, join='inner')\n",
    "    result.columns=columns_name\n",
    "    return result, columns_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ed91dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_files(url):\n",
    "    try:\n",
    "        urlopen(url)\n",
    "        print(\"URL is valid\")\n",
    "        links = []\n",
    "        html = urlopen(url).read()\n",
    "        html_page = bs(html, features=\"lxml\")\n",
    "        og_url = html_page.find(\"meta\",  property = \"og:url\")\n",
    "        for link in html_page.find_all('a', href=True):\n",
    "            current_link = link.get('href')\n",
    "            last_under = current_link.rfind('?')\n",
    "            current_link = current_link[:last_under]\n",
    "            if current_link.endswith('pdf'):\n",
    "                if og_url:\n",
    "                    #print(\"currentLink:\",current_link)\n",
    "                    links.append(\"https://www.mba.org\" + current_link)\n",
    "    except IOError:\n",
    "        print (\"URL is invalid, please check out the URL!\")\n",
    "        sys.exit()\n",
    "    print(\"All available pdf links:\", links)\n",
    "     \n",
    "    if os.stat(\"archievelinks.csv\").st_size == 0:\n",
    "        df = pd.DataFrame(links).drop_duplicates(keep='first')\n",
    "        current_link = df.values\n",
    "        iteration = len(current_link)\n",
    "    else:\n",
    "        path_directory =  os.getcwd()\n",
    "        archievelinks_data = pd.read_csv(\"archievelinks.csv\", header=None)\n",
    "        new_archievelinks_data = pd.DataFrame(links).drop_duplicates(keep='first')\n",
    "        df_diff_archievelinks = pd.concat([new_archievelinks_data, archievelinks_data]).drop_duplicates(keep=False)\n",
    "        if df_diff_archievelinks.empty:\n",
    "            print('There is no newly added file !')\n",
    "            return df_diff_archievelinks\n",
    "        else:\n",
    "            df = df_diff_archievelinks\n",
    "            current_link = df.values\n",
    "            iteration = len(current_link)\n",
    "                \n",
    "    for i in range(iteration):\n",
    "        pattern1 = str(current_link[i]).rfind('source')+7\n",
    "        pattern2 = str(current_link[i])[pattern1:]\n",
    "        pattern3 = str(current_link[i]).rfind('forecast')+9\n",
    "        pattern4 = str(current_link[i])[pattern3:-2]\n",
    "        while True:\n",
    "            r = requests.get(f\"https://www.mba.org/docs/default-source/{pattern2}\")\n",
    "            if r.status_code == 200:\n",
    "                completeName = os.path.join(directory_name, f\"{pattern4}\")            \n",
    "                pattern_name = pattern4[0:-4]+\".csv\"\n",
    "                completeName_csv = os.path.join(csv_directory_name, f\"{pattern_name}\")\n",
    "                \n",
    "                with open(completeName, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                    print(f\"File Downloaded and Saved As: {pattern4}\")\n",
    "                \n",
    "                with open(completeName_csv, 'wb') as f1:\n",
    "                    result, columns_name = extract_pdf_data(pattern4)\n",
    "                    pattern_name = pattern4[0:-4]\n",
    "                    result.to_csv(completeName_csv, index=False, header=columns_name) \n",
    "                    print(f\"Table Data of {pattern4} is Extracted and Saved As: {pattern_name}.csv\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"File Not Raised Yet, We Will Check Back After One Day.\")\n",
    "                sleep(3600)\n",
    "                continue\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7603409e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL is valid\n",
      "All available pdf links: ['https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-aug-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-july-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-june-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-june-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-may-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-apr-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-mar-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/mortgage-finance-forecast-feb-2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/res_sf_mortgage_finance_forecast_jan_2022.pdf', 'https://www.mba.org/docs/default-source/research-and-forecasts/forecasts/res_sf_mortgage_finance_forecast_dec_2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-nov-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-oct-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-sep-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-aug-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-jul-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-jun-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-may-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-apr-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-mar-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-feb-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-jan-2021.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-dec-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-nov-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-oct-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-sep-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-aug-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-jul-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-june-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-may-2020.pdf', 'https://www.mba.org/docs/default-source/uploadedfiles/research/mortgage-finance-forecast-apr-2020.pdf']\n",
      "File Downloaded and Saved As: aug-2022.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 23:19:45,424 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Data of aug-2022.pdf is Extracted and Saved As: aug-2022.csv\n",
      "File Downloaded and Saved As: july-2022.pdf\n",
      "Table Data of july-2022.pdf is Extracted and Saved As: july-2022.csv\n",
      "File Downloaded and Saved As: june-2022.pdf\n",
      "Table Data of june-2022.pdf is Extracted and Saved As: june-2022.csv\n",
      "File Downloaded and Saved As: may-2022.pdf\n",
      "Table Data of may-2022.pdf is Extracted and Saved As: may-2022.csv\n",
      "File Downloaded and Saved As: apr-2022.pdf\n",
      "Table Data of apr-2022.pdf is Extracted and Saved As: apr-2022.csv\n",
      "File Downloaded and Saved As: mar-2022.pdf\n",
      "Table Data of mar-2022.pdf is Extracted and Saved As: mar-2022.csv\n",
      "File Downloaded and Saved As: feb-2022.pdf\n",
      "Table Data of feb-2022.pdf is Extracted and Saved As: feb-2022.csv\n",
      "File Downloaded and Saved As: jan_2022.pdf\n",
      "Table Data of jan_2022.pdf is Extracted and Saved As: jan_2022.csv\n",
      "File Downloaded and Saved As: dec_2021.pdf\n",
      "Table Data of dec_2021.pdf is Extracted and Saved As: dec_2021.csv\n",
      "File Downloaded and Saved As: nov-2021.pdf\n",
      "Table Data of nov-2021.pdf is Extracted and Saved As: nov-2021.csv\n",
      "File Downloaded and Saved As: oct-2021.pdf\n",
      "Table Data of oct-2021.pdf is Extracted and Saved As: oct-2021.csv\n",
      "File Downloaded and Saved As: sep-2021.pdf\n",
      "Table Data of sep-2021.pdf is Extracted and Saved As: sep-2021.csv\n",
      "File Downloaded and Saved As: aug-2021.pdf\n",
      "Table Data of aug-2021.pdf is Extracted and Saved As: aug-2021.csv\n",
      "File Downloaded and Saved As: jul-2021.pdf\n",
      "Table Data of jul-2021.pdf is Extracted and Saved As: jul-2021.csv\n",
      "File Downloaded and Saved As: jun-2021.pdf\n",
      "Table Data of jun-2021.pdf is Extracted and Saved As: jun-2021.csv\n",
      "File Downloaded and Saved As: may-2021.pdf\n",
      "Table Data of may-2021.pdf is Extracted and Saved As: may-2021.csv\n",
      "File Downloaded and Saved As: apr-2021.pdf\n",
      "Table Data of apr-2021.pdf is Extracted and Saved As: apr-2021.csv\n",
      "File Downloaded and Saved As: mar-2021.pdf\n",
      "Table Data of mar-2021.pdf is Extracted and Saved As: mar-2021.csv\n",
      "File Downloaded and Saved As: feb-2021.pdf\n",
      "Table Data of feb-2021.pdf is Extracted and Saved As: feb-2021.csv\n",
      "File Downloaded and Saved As: jan-2021.pdf\n",
      "Table Data of jan-2021.pdf is Extracted and Saved As: jan-2021.csv\n",
      "File Downloaded and Saved As: dec-2020.pdf\n",
      "Table Data of dec-2020.pdf is Extracted and Saved As: dec-2020.csv\n",
      "File Downloaded and Saved As: nov-2020.pdf\n",
      "Table Data of nov-2020.pdf is Extracted and Saved As: nov-2020.csv\n",
      "File Downloaded and Saved As: oct-2020.pdf\n",
      "Table Data of oct-2020.pdf is Extracted and Saved As: oct-2020.csv\n",
      "File Downloaded and Saved As: sep-2020.pdf\n",
      "Table Data of sep-2020.pdf is Extracted and Saved As: sep-2020.csv\n",
      "File Downloaded and Saved As: aug-2020.pdf\n",
      "Table Data of aug-2020.pdf is Extracted and Saved As: aug-2020.csv\n",
      "File Downloaded and Saved As: jul-2020.pdf\n",
      "Table Data of jul-2020.pdf is Extracted and Saved As: jul-2020.csv\n",
      "File Downloaded and Saved As: june-2020.pdf\n",
      "Table Data of june-2020.pdf is Extracted and Saved As: june-2020.csv\n",
      "File Downloaded and Saved As: may-2020.pdf\n",
      "Table Data of may-2020.pdf is Extracted and Saved As: may-2020.csv\n",
      "File Downloaded and Saved As: apr-2020.pdf\n",
      "Table Data of apr-2020.pdf is Extracted and Saved As: apr-2020.csv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.mba.org/news-and-research/forecasts-and-commentary/mortgage-finance-forecast-archives\"\n",
    "\n",
    "directory_name = \"archievefiles\"\n",
    "csv_directory_name = \"archivecsvfiles\"\n",
    "\n",
    "if os.path.isfile('archievelinks.csv')==False and os.path.exists(directory_name)==False and os.path.exists(csv_directory_name)==False:\n",
    "    path_directory =  os.getcwd()\n",
    "    pdf_links = open('archievelinks.csv','a+')\n",
    "    \n",
    "    os.mkdir(os.path.join(path_directory, directory_name))\n",
    "    Path('archievefiles').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    os.mkdir(os.path.join(path_directory, csv_directory_name))\n",
    "    Path('archivecsvfiles').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df = get_pdf_files(url)\n",
    "    df = df.reindex(index=df.index[::-1])\n",
    "    df.to_csv('archievelinks.csv', index=False, header=None)\n",
    "    pdf_links.close()\n",
    "else:\n",
    "    pdf_links = open('archievelinks.csv','r')\n",
    "    df = get_pdf_files(url)\n",
    "    df = df.reindex(index=df.index[::-1])\n",
    "    df.to_csv('archievelinks.csv', mode = \"a\", index=False, header=None)\n",
    "    pdf_links.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
